{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "# path_to_file = tf.keras.utils.get_file('iliad.txt', 'http://classics.mit.edu/Homer/iliad.mb.txt')\n",
    "# path_to_file = 'C:/Users/Toby-PC/Desktop/mccarthy/'\n",
    "path_to_file = 'C:/Users/Toby-PC/Desktop/got.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 7469809 characters\n"
     ]
    }
   ],
   "source": [
    "# text = ''\n",
    "# for i in range(5):\n",
    "#     ext = \"{}.txt\".format(i+1)\n",
    "#     path = path_to_file + ext\n",
    "#     newtext = open(path, 'rb').read().decode(encoding='utf-8')\n",
    "#     text += newtext\n",
    "    \n",
    "# text_file = open(\"mccarthy.txt\", \"w\")\n",
    "# text_file.write(text)\n",
    "# text_file.close()\n",
    "\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "\n",
    "# length of text is the number of characters in it\n",
    "print ('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTENTS\r\n",
      "\r\n",
      "\r\n",
      "COVER\r\n",
      "\r\n",
      "TITLE PAGE\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "A GAME OF THRONES\r\n",
      "\r\n",
      "A CLASH OF KINGS\r\n",
      "\r\n",
      "A STORM OF SWORDS\r\n",
      "\r\n",
      "A FEAST FOR CROWS\r\n",
      "\r\n",
      "ABOUT THE AUTHOR\r\n",
      "\r\n",
      "ALSO BY GEORGE R.R. MARTIN\r\n",
      "\r\n",
      "EXCERPT FROM A DANCE WITH DRAGONS\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "A Game of Thrones\r\n",
      "\r\n",
      "A Bantam S\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the first 250 characters in text\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 unique characters\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "\n",
    "vocab = sorted(set(text))\n",
    "print ('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\t', '\\n', '\\r', ' ', '!', \"'\", '(', ')', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '}', '©', 'é', 'ê', 'í', '–', '—', '‘', '’', '“', '”', '…']\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  '\\t':   0,\n",
      "  '\\n':   1,\n",
      "  '\\r':   2,\n",
      "  ' ' :   3,\n",
      "  '!' :   4,\n",
      "  \"'\" :   5,\n",
      "  '(' :   6,\n",
      "  ')' :   7,\n",
      "  ',' :   8,\n",
      "  '-' :   9,\n",
      "  '.' :  10,\n",
      "  '/' :  11,\n",
      "  '0' :  12,\n",
      "  '1' :  13,\n",
      "  '2' :  14,\n",
      "  '3' :  15,\n",
      "  '4' :  16,\n",
      "  '5' :  17,\n",
      "  '6' :  18,\n",
      "  '7' :  19,\n",
      "  ...\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('{')\n",
    "for char,_ in zip(char2idx, range(20)):\n",
    "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
    "print('  ...\\n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'CONTENTS\\r\\n\\r\\n\\r' ---- characters mapped to int ---- > [27 39 38 44 29 38 44 43  2  1  2  1  2]\n"
     ]
    }
   ],
   "source": [
    "# Show how the first 13 characters from the text are mapped to integers\n",
    "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:13]), text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Toby-PC\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:532: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "C\n",
      "O\n",
      "N\n",
      "T\n",
      "E\n"
     ]
    }
   ],
   "source": [
    "# The maximum length sentence we want for a single input in characters\n",
    "seq_length = 500\n",
    "examples_per_epoch = len(text)//seq_length\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "  print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'CONTENTS\\r\\n\\r\\n\\r\\nCOVER\\r\\n\\r\\nTITLE PAGE\\r\\n\\r\\n\\r\\n\\r\\nA GAME OF THRONES\\r\\n\\r\\nA CLASH OF KINGS\\r\\n\\r\\nA STORM OF SWORDS\\r\\n\\r\\nA FEAST FOR CROWS\\r\\n\\r\\nABOUT THE AUTHOR\\r\\n\\r\\nALSO BY GEORGE R.R. MARTIN\\r\\n\\r\\nEXCERPT FROM A DANCE WITH DRAGONS\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nA Game of Thrones\\r\\n\\r\\nA Bantam Spectra Book\\r\\n\\r\\nSPECTRA and the portrayal of a boxed “s” are trademarks of Bantam Books, a division of Random House, Inc.\\r\\n\\r\\nPUBLISHING HISTORY\\r\\n\\r\\nBantam hardcover edition published September 1996\\r\\n\\r\\nBantam paperback edition / September 1997\\r\\n\\r\\nMaps by'\n",
      "' James Sinclair.\\r\\n\\r\\nHeraldic crests by Virginia Norey.\\r\\n\\r\\nAll rights reserved.\\r\\n\\r\\nCopyright © 1996 by George R. R. Martin\\r\\n\\r\\nLibrary of Congress Catalog Card Number: 95-43936.\\r\\n\\r\\nNo part of this book may be reproduced or transmitted in any form\\r\\n\\r\\nor by any means, electronic or mechanical, including photocopying,\\r\\n\\r\\nrecording, or by any information storage and retrieval system,\\r\\n\\r\\nwithout permission in writing from the publisher.\\r\\n\\r\\nFor information address: Bantam Books.\\r\\n\\r\\nVisit our website at w'\n",
      "'ww.bantamdell.com\\r\\n\\r\\neISBN: 978-0-553-89784-5\\r\\n\\r\\n\\r\\nBantam Books are published by Bantam Books, a division of Random House, Inc. Its trademark, consisting of the words “Bantam Books” and the portrayal of a rooster, is Registered in U.S. Patent and Trademark Office and in other countries. Marca Registrada. Bantam Books, 1540 Broadway, New York, New York 10036.\\r\\n\\r\\n\\r\\n\\r\\nv3.1_r2\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nthis one is for Melinda\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nCONTENTS\\r\\n\\r\\n\\r\\nCOVER\\r\\n\\r\\nTITLE PAGE\\r\\n\\r\\nCOPYRIGHT\\r\\n\\r\\nDEDICATION\\r\\n\\r\\nMAPS\\r\\n\\r\\nPROLOGU'\n",
      "'E\\r\\n\\r\\n\\r\\n\\r\\nBRAN\\r\\n\\r\\nCATELYN\\r\\n\\r\\nDAENERYS\\r\\n\\r\\nEDDARD\\r\\n\\r\\nJON\\r\\n\\r\\nCATELYN\\r\\n\\r\\nARYA\\r\\n\\r\\nBRAN\\r\\n\\r\\nTYRION\\r\\n\\r\\nJON\\r\\n\\r\\nDAENERYS\\r\\n\\r\\nEDDARD\\r\\n\\r\\nTYRION\\r\\n\\r\\nCATELYN\\r\\n\\r\\nSANSA\\r\\n\\r\\nEDDARD\\r\\n\\r\\nBRAN\\r\\n\\r\\nCATELYN\\r\\n\\r\\nJON\\r\\n\\r\\nEDDARD\\r\\n\\r\\nTYRION\\r\\n\\r\\nARYA\\r\\n\\r\\nDAENERYS\\r\\n\\r\\nBRAN\\r\\n\\r\\nEDDARD\\r\\n\\r\\nJON\\r\\n\\r\\nEDDARD\\r\\n\\r\\nCATELYN\\r\\n\\r\\nSANSA\\r\\n\\r\\nEDDARD\\r\\n\\r\\nTYRION\\r\\n\\r\\nARYA\\r\\n\\r\\nEDDARD\\r\\n\\r\\nCATELYN\\r\\n\\r\\nEDDARD\\r\\n\\r\\nDAENERYS\\r\\n\\r\\nBRAN\\r\\n\\r\\nTYRION\\r\\n\\r\\nEDDARD\\r\\n\\r\\nCATELYN\\r\\n\\r\\nJON\\r\\n\\r\\nTYRION\\r\\n\\r\\nEDDARD\\r\\n\\r\\nSANSA\\r\\n\\r\\nEDDARD\\r\\n\\r\\nDAENERYS\\r\\n\\r\\nEDDARD\\r\\n\\r\\nJON\\r\\n\\r\\nEDDARD\\r\\n\\r\\nARYA\\r\\n\\r\\nSANSA\\r\\n\\r\\nJON\\r\\n'\n",
      "'\\r\\nBRAN\\r\\n\\r\\nDAENERYS\\r\\n\\r\\nCATELYN\\r\\n\\r\\nTYRION\\r\\n\\r\\nSANSA\\r\\n\\r\\nEDDARD\\r\\n\\r\\nCATELYN\\r\\n\\r\\nJON\\r\\n\\r\\nDAENERYS\\r\\n\\r\\nTYRION\\r\\n\\r\\nCATELYN\\r\\n\\r\\nDAENERYS\\r\\n\\r\\nARYA\\r\\n\\r\\nBRAN\\r\\n\\r\\nSANSA\\r\\n\\r\\nDAENERYS\\r\\n\\r\\nTYRION\\r\\n\\r\\nJON\\r\\n\\r\\nCATELYN\\r\\n\\r\\nDAENERYS\\r\\n\\r\\nAPPENDIX\\r\\n\\r\\nHOUSE BARATHEON\\r\\n\\r\\nHOUSE STARK\\r\\n\\r\\nHOUSE LANNISTER\\r\\n\\r\\nHOUSE ARRYN\\r\\n\\r\\nHOUSE TULLY\\r\\n\\r\\nHOUSE TYRELL\\r\\n\\r\\nHOUSE GREYJOY\\r\\n\\r\\nHOUSE MARTELL\\r\\n\\r\\nTHE OLD DYNASTY HOUSE TARGARYEN\\r\\n\\r\\nACKNOWLEDGMENTS\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nPROLOGUE\\r\\n\\r\\n\\r\\n“We should start back,” Gared urged as the woods began to grow dark around the'\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "  print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'CONTENTS\\r\\n\\r\\n\\r\\nCOVER\\r\\n\\r\\nTITLE PAGE\\r\\n\\r\\n\\r\\n\\r\\nA GAME OF THRONES\\r\\n\\r\\nA CLASH OF KINGS\\r\\n\\r\\nA STORM OF SWORDS\\r\\n\\r\\nA FEAST FOR CROWS\\r\\n\\r\\nABOUT THE AUTHOR\\r\\n\\r\\nALSO BY GEORGE R.R. MARTIN\\r\\n\\r\\nEXCERPT FROM A DANCE WITH DRAGONS\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nA Game of Thrones\\r\\n\\r\\nA Bantam Spectra Book\\r\\n\\r\\nSPECTRA and the portrayal of a boxed “s” are trademarks of Bantam Books, a division of Random House, Inc.\\r\\n\\r\\nPUBLISHING HISTORY\\r\\n\\r\\nBantam hardcover edition published September 1996\\r\\n\\r\\nBantam paperback edition / September 1997\\r\\n\\r\\nMaps b'\n",
      "Target data: 'ONTENTS\\r\\n\\r\\n\\r\\nCOVER\\r\\n\\r\\nTITLE PAGE\\r\\n\\r\\n\\r\\n\\r\\nA GAME OF THRONES\\r\\n\\r\\nA CLASH OF KINGS\\r\\n\\r\\nA STORM OF SWORDS\\r\\n\\r\\nA FEAST FOR CROWS\\r\\n\\r\\nABOUT THE AUTHOR\\r\\n\\r\\nALSO BY GEORGE R.R. MARTIN\\r\\n\\r\\nEXCERPT FROM A DANCE WITH DRAGONS\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nA Game of Thrones\\r\\n\\r\\nA Bantam Spectra Book\\r\\n\\r\\nSPECTRA and the portrayal of a boxed “s” are trademarks of Bantam Books, a division of Random House, Inc.\\r\\n\\r\\nPUBLISHING HISTORY\\r\\n\\r\\nBantam hardcover edition published September 1996\\r\\n\\r\\nBantam paperback edition / September 1997\\r\\n\\r\\nMaps by'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 27 ('C')\n",
      "  expected output: 39 ('O')\n",
      "Step    1\n",
      "  input: 39 ('O')\n",
      "  expected output: 38 ('N')\n",
      "Step    2\n",
      "  input: 38 ('N')\n",
      "  expected output: 44 ('T')\n",
      "Step    3\n",
      "  input: 44 ('T')\n",
      "  expected output: 29 ('E')\n",
      "Step    4\n",
      "  input: 29 ('E')\n",
      "  expected output: 38 ('N')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((256, 500), (256, 500)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size \n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = examples_per_epoch//BATCH_SIZE\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences, \n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead, \n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension \n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = tf.keras.layers.CuDNNGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, \n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    rnn(rnn_units,\n",
    "        return_sequences=True, \n",
    "        recurrent_initializer='glorot_uniform',\n",
    "        stateful=True),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocab_size = len(vocab), \n",
    "  embedding_dim=embedding_dim, \n",
    "  rnn_units=rnn_units, \n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for input_example_batch, target_example_batch in dataset.take(1): \n",
    "#   example_batch_predictions = model(input_example_batch)\n",
    "#   print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (256, None, 256)          23808     \n",
      "_________________________________________________________________\n",
      "cu_dnngru (CuDNNGRU)         (256, None, 1024)         3938304   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (256, None, 93)           95325     \n",
      "=================================================================\n",
      "Total params: 4,057,437\n",
      "Trainable params: 4,057,437\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "# print(sampled_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
    "# print(sampled_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "# print()\n",
    "# print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard tf.keras.losses.sparse_softmax_crossentropy loss function works in this case because it is applied across the last dimension of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "# example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
    "# print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\") \n",
    "# print(\"Target shape:      \", target_example_batch.shape)\n",
    "# print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = tf.train.AdamOptimizer(),\n",
    "    loss = loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "57/58 [============================>.] - ETA: 0s - loss: 3.4229WARNING:tensorflow:From C:\\Users\\Toby-PC\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py:1436: update_checkpoint_state (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.train.CheckpointManager to manage checkpoints rather than manually editing the Checkpoint proto.\n",
      "58/58 [==============================] - 39s 679ms/step - loss: 3.4077\n",
      "Epoch 2/20\n",
      "58/58 [==============================] - 38s 652ms/step - loss: 2.3362\n",
      "Epoch 3/20\n",
      "58/58 [==============================] - 38s 653ms/step - loss: 2.1293\n",
      "Epoch 4/20\n",
      "58/58 [==============================] - 38s 663ms/step - loss: 1.9544\n",
      "Epoch 5/20\n",
      "58/58 [==============================] - 38s 659ms/step - loss: 1.7958\n",
      "Epoch 6/20\n",
      "58/58 [==============================] - 38s 655ms/step - loss: 1.6605\n",
      "Epoch 7/20\n",
      "58/58 [==============================] - 38s 662ms/step - loss: 1.5511\n",
      "Epoch 8/20\n",
      "58/58 [==============================] - 39s 672ms/step - loss: 1.4655\n",
      "Epoch 9/20\n",
      "58/58 [==============================] - 39s 666ms/step - loss: 1.3997\n",
      "Epoch 10/20\n",
      "58/58 [==============================] - 38s 658ms/step - loss: 1.3491\n",
      "Epoch 11/20\n",
      "58/58 [==============================] - 38s 661ms/step - loss: 1.3089\n",
      "Epoch 12/20\n",
      "58/58 [==============================] - 38s 663ms/step - loss: 1.2780\n",
      "Epoch 13/20\n",
      "24/58 [===========>..................] - ETA: 24s - loss: 1.2546"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset.repeat(), epochs=EPOCHS, steps_per_epoch=steps_per_epoch, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "  # Evaluation step (generating text using the learned model)\n",
    "\n",
    "  # Number of characters to generate\n",
    "  num_generate = 1000\n",
    "\n",
    "  # Converting our start string to numbers (vectorizing) \n",
    "  input_eval = [char2idx[s] for s in start_string]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  # Empty string to store our results\n",
    "  text_generated = []\n",
    "\n",
    "  # Low temperatures results in more predictable text.\n",
    "  # Higher temperatures results in more surprising text.\n",
    "  # Experiment to find the best setting.\n",
    "  temperature = 0.5\n",
    "\n",
    "  # Here batch size == 1\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "      predictions = model(input_eval)\n",
    "      # remove the batch dimension\n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      # using a multinomial distribution to predict the word returned by the model\n",
    "      predictions = predictions / temperature\n",
    "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "      \n",
    "      # We pass the predicted word as the next input to the model\n",
    "      # along with the previous hidden state\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "      \n",
    "      text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_text(model, start_string=u\"Incandenza \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    ext = \"{}.txt\".format(i)\n",
    "    print(ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
